---
title: Agent 设计理念与实践经验
date: 2026-02-14
category: AI/架构设计
tags: [agent,  design,  prompt,  evaluation,  deployment,  context]
source: 
---

# Agent 设计理念与实践经验

## 原始用户输入

```
实践总结：

research agent的prompt原则：
像你的agent一样思考：构建模拟环境，逐步观察agent的工作过程。发现一些可能的失败：agent已经获得足够结果仍继续运行、使用冗长的搜索查询、选择错误的tool

教agent里的orchestrator如何委派任务：主 agent 将查询分解为子任务并将其描述给子 agent。每个子 agent 都需要一个目标、一种输出格式、关于要使用的工具和来源的指导，以及明确的任务边界。

根据查询复杂度scale effort：简单的任务仅需一个agent进行3到10次toolcall；直接对比可能需要2到4个agent，每个进行10到15次toolcall；复杂的agent可能需要10个以上职责分明的子agent

工具设计与选择很重要：为 Agent 提供了明确的启发式策略：例如，首先检查所有可用工具，将工具使用与用户意图匹配，利用 Web 搜索进行广泛的外部探索，或者优先选择专用工具而非通用工具

让agent自我改进：当给定一个 prompt 和一种失败模式时，它们能够诊断出 agent 失败的原因并提出改进建议

先广后深，逐步聚焦：通过提示词引导 Agent 从简短、宽泛的查询开始，评估现有信息，然后逐步缩小关注范围

引导思考过程：引导 Claude 在可见的思考过程中输出额外的 token，extended thinking 提升了指令遵循能力、推理能力和效率

并行 tool calling 极大地提升了速度和性能

总结：提示词策略侧重于灌输良好的启发式方法，而非死板的规则，还通过设置明确的护栏来主动减轻意外的副作用，防止 agent 失去控制。最后，专注于通过可观测性和测试用例实现快速迭代循环。

对agent的评估：
使用一个 LLM 裁判，根据评分表中的标准对每个产出进行评估：事实准确性（陈述是否与来源一致？）、引用准确性（引用的来源是否支持陈述？）、完整性（是否涵盖了所有要求的方面？）、来源质量（是否优先使用了初级来源而非低质量的次级来源？）以及工具效率（是否以合理的次数使用了正确的工具？）

尝试过使用多个裁判来评估每个组件，但发现使用单个 prompt 进行一次 LLM 调用，并输出 0.0-1.0 的分数以及通过/失败的等级，是最一致且最符合人类判断的方法

与其判断 agent 是否遵循了特定的过程，不如评估它是否达到了正确的最终状态。这种方法承认 agent 可能会找到实现同一目标的替代路径，同时仍能确保它们交付预期的结果。对于复杂的工作流，应将评估分解为应发生特定状态变化的离散检查点，而不是试图验证每一个中间步骤。

agent的部署：采用 rainbow deployments（彩虹部署）来避免干扰正在运行的 Agent，通过将流量从旧版本逐渐迁移到新版本，同时保持两者并行运行。

上下文的处理：
让 agent 在进入新任务之前总结已完成的工作阶段，并将关键信息存储在外部记忆中。当接近上下文限制时，agent 可以生成带有干净上下文的新子 agent，同时通过细致的交接保持连续性

新agent从记忆中检索存储的上下文（如研究计划），而不是在达到上下文限制时丢失之前的工作

子代理调用 tool 将其工作存储在外部系统中，然后将轻量级引用传回协调器。这可以防止多阶段处理过程中的信息丢失，并减少因在对话历史中复制大量输出而产生的 token 开销
```

---

## 结构化内容

实践总结：
research agent的prompt原则：
像你的agent一样思考：构建模拟环境，逐步观察agent的工作过程。发现一些可能的失败：agent已经获得足够结果仍继续运行、使用冗长的搜索查询、选择错误的tool
教agent里的orchestrator如何委派任务：主 agent 将查询分解为子任务并将其描述给子 agent。每个子 agent 都需要一个目标、一种输出格式、关于要使用的工具和来源的指导，以及明确的任务边界。
根据查询复杂度scale effort：简单的任务仅需一个agent进行3到10次toolcall；直接对比可能需要2到4个agent，每个进行10到15次toolcall；复杂的agent可能需要10个以上职责分明的子agent
工具设计与选择很重要：为 Agent 提供了明确的启发式策略：例如，首先检查所有可用工具，将工具使用与用户意图匹配，利用 Web 搜索进行广泛的外部探索，或者优先选择专用工具而非通用工具
让agent自我改进：当给定一个 prompt 和一种失败模式时，它们能够诊断出 agent 失败的原因并提出改进建议
先广后深，逐步聚焦：通过提示词引导 Agent 从简短、宽泛的查询开始，评估现有信息，然后逐步缩小关注范围
引导思考过程：引导 Claude 在可见的思考过程中输出额外的 token，extended thinking 提升了指令遵循能力、推理能力和效率
并行 tool calling 极大地提升了速度和性能

### 总结：提示词策略侧重于灌输良好的启发式方法，而非死板的规则，还通过设置明确的护栏来主动减轻意外的副作用，防止 agent 失去控制。最后，专注于通过可观测性和测试用例实现快速迭代循环。

对agent的评估：
使用一个 LLM 裁判，根据评分表中的标准对每个产出进行评估：事实准确性（陈述是否与来源一致？）、引用准确性（引用的来源是否支持陈述？）、完整性（是否涵盖了所有要求的方面？）、来源质量（是否优先使用了初级来源而非低质量的次级来源？）以及工具效率（是否以合理的次数使用了正确的工具？）

### 尝试过使用多个裁判来评估每个组件，但发现使用单个 prompt 进行一次 LLM 调用，并输出 0.0-1.0 的分数以及通过/失败的等级，是最一致且最符合人类判断的方法


### 与其判断 agent 是否遵循了特定的过程，不如评估它是否达到了正确的最终状态。这种方法承认 agent 可能会找到实现同一目标的替代路径，同时仍能确保它们交付预期的结果。对于复杂的工作流，应将评估分解为应发生特定状态变化的离散检查点，而不是试图验证每一个中间步骤。

agent的部署：采用 rainbow deployments（彩虹部署）来避免干扰正在运行的 Agent，通过将流量从旧版本逐渐迁移到新版本，同时保持两者并行运行。
上下文的处理：
让 agent 在进入新任务之前总结已完成的工作阶段，并将关键信息存储在外部记忆中。当接近上下文限制时，agent 可以生成带有干净上下文的新子 agent，同时通过细致的交接保持连续性
新agent从记忆中检索存储的上下文（如研究计划），而不是在达到上下文限制时丢失之前的工作
子代理调用 tool 将其工作存储在外部系统中，然后将轻量级引用传回协调器。这可以防止多阶段处理过程中的信息丢失，并减少因在对话历史中复制大量输出而产生的 token 开销

---
*Created by Inspiration Manager*
*Timestamp: 2026-02-14*
