---
title: Agent 设计理念与实践经验
date: 2026-02-14
category: AI/架构设计
tags: [agent, design, prompt, evaluation, deployment, context]
source: 
---

# Agent 设计理念与实践经验

## 原始用户输入

```
research agent的prompt原则：
像你的agent一样思考：构建模拟环境，逐步观察agent的工作过程。发现一些可能的失败：agent已经获得足够结果仍继续运行、使用冗长的搜索查询、选择错误的tool

教agent里的orchestrator如何委派任务：主 agent 将查询分解为子任务并将其描述给子 agent。每个子 agent 都需要一个目标、一种输出格式、关于要使用的工具和来源的指导，以及明确的任务边界。

根据查询复杂度scale effort：简单的任务仅需一个agent进行3到10次toolcall；直接对比可能需要2到4个agent，每个进行10到15次toolcall；复杂的agent可能需要10个以上职责分明的子agent

工具设计与选择很重要：为 Agent 提供了明确的启发式策略：例如，首先检查所有可用工具，将工具使用与用户意图匹配，利用 Web 搜索进行广泛的外部探索，或者优先选择专用工具而非通用工具

让agent自我改进：当给定一个 prompt 和一种失败模式时，它们能够诊断出 agent 失败的原因并提出改进建议

先广后深，逐步聚焦：通过提示词引导 Agent 从简短、宽泛的查询开始，评估现有信息，然后逐步缩小关注范围

引导思考过程：引导 Claude 在可见的思考过程中输出额外的 token，extended thinking 提升了指令遵循能力、推理能力和效率

并行 tool calling 极大地提升了速度和性能

总结：提示词策略侧重于灌输良好的启发式方法，而非死板的规则，还通过设置明确的护栏来主动减轻意外的副作用，防止 agent 失去控制。最后，专注于通过可观测性和测试用例实现快速迭代循环。

对agent的评估：
使用一个 LLM 裁判，根据评分表中的标准对每个产出进行评估：事实准确性（陈述是否与来源一致？）、引用准确性（引用的来源是否支持陈述？）、完整性（是否涵盖了所有要求的方面？）、来源质量（是否优先使用了初级来源而非低质量的次级来源？）以及工具效率（是否以合理的次数使用了正确的工具？）

尝试过使用多个裁判来评估每个组件，但发现使用单个 prompt 进行一次 LLM 调用，并输出 0.0-1.0 的分数以及通过/失败的等级，是最一致且最符合人类判断的方法

与其判断 agent 是否遵循了特定的过程，不如评估它是否达到了正确的最终状态。这种方法承认 agent 可能会找到实现同一目标的替代路径，同时仍能确保它们交付预期的结果。对于复杂的工作流，应将评估分解为应发生特定状态变化的离散检查点，而不是试图验证每一个中间步骤。

agent的部署：采用 rainbow deployments（彩虹部署）来避免干扰正在运行的 Agent，通过将流量从旧版本逐渐迁移到新版本，同时保持两者并行运行。

上下文的处理：
让 agent 在进入新任务之前总结已完成的工作阶段，并将关键信息存储在外部记忆中。当接近上下文限制时，agent 可以生成带有干净上下文的新子 agent，同时通过细致的交接保持连续性

新agent从记忆中检索存储的上下文（如研究计划），而不是在达到上下文限制时丢失之前的工作

子代理调用 tool 将其工作存储在外部系统中，然后将轻量级引用传回协调器。这可以防止多阶段处理过程中的信息丢失，并减少因在对话历史中复制大量输出而产生的 token 开销
```

---

## 结构化内容

### 一、Prompt 设计原则

| 原则 | 说明 |
|------|------|
| **像你的 agent 一样思考** | 构建模拟环境，逐步观察 agent 工作过程，发现潜在失败模式 |
| **先广后深，逐步聚焦** | 从简短宽泛查询开始，评估现有信息，再逐步缩小范围 |
| **引导思考过程** | 引导 Claude 输出 extended thinking，提升推理能力和效率 |
| **灌输启发式方法，而非死板规则** | 设置明确护栏，主动减轻意外副作用 |

### 二、Orchestrator 委派模式

| 项目 | 内容 |
|------|------|
| **主 agent 职责** | 将查询分解为子任务，描述给子 agent |
| **子 agent 需要** | 目标、输出格式、工具和来源指导、明确任务边界 |

### 三、根据复杂度 Scale Effort

| 复杂度 | Agent 数量 | Tool Call 次数 |
|--------|------------|----------------|
| 简单 | 1 个 agent | 3-10 次 |
| 直接对比 | 2-4 个 agent | 每个 10-15 次 |
| 复杂 | 10+ 个子 agent | 职责分明 |

### 四、工具设计

| 策略 | 说明 |
|------|------|
| 检查所有可用工具 | 了解工具能力边界 |
| 工具与意图匹配 | 将工具使用与用户意图对齐 |
| 外部探索 | 利用 Web 搜索进行广泛探索 |
| 专用优先 | 优先选择专用工具而非通用工具 |

### 五、Agent 自我改进

- 当给定 prompt 和失败模式时，agent 能诊断失败原因并提出改进建议

### 六、评估方法

| 维度 | 评估标准 |
|------|----------|
| 事实准确性 | 陈述是否与来源一致 |
| 引用准确性 | 引用的来源是否支持陈述 |
| 完整性 | 是否覆盖所有要求的方面 |
| 来源质量 | 是否优先使用初级来源 |
| 工具效率 | 是否以合理次数使用正确工具 |

**最佳实践**：
- 使用单个 prompt 进行一次 LLM 调用
- 输出 0.0-1.0 分数 + 通过/失败等级
- 评估最终状态而非过程（允许替代路径）
- 复杂工作流：分解为离散检查点

### 七、部署策略

**Rainbow Deployments**：
- 避免干扰正在运行的 Agent
- 流量从旧版本逐渐迁移到新版本
- 旧新版本并行运行

### 八、上下文处理

| 策略 | 说明 |
|------|------|
| **工作阶段总结** | 进入新任务前总结已完成工作，存储到外部记忆 |
| **上下文接近限制时** | 生成带有干净上下文的新子 agent，通过细致交接保持连续性 |
| **从记忆检索** | 新 agent 从记忆检索上下文（如研究计划） |
| **轻量级引用** | 子代理将工作存储在外部系统，传回引用而非完整输出 |

### 九、性能优化

| 优化点 | 效果 |
|--------|------|
| 并行 tool calling | 大幅提升速度和性能 |

---

*Created by Inspiration Manager*
*Timestamp: 2026-02-14*
